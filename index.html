<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Dingding Cai</title>
  
  <meta name="author" content="Dingding Cai">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/jpg" href="images/dingdingcai.jpg">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          
          <!-- introduction -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Dingding Cai</name>
                  </p>
                  <p>
                    Currently, I am a PhD candidate in the <a href="https://research.tuni.fi/vision">Computer Vision Group at Tampere University, Finland</a>, 
                    where I am working on 3D computer vision and machine learning, specializing in 6D object pose estimation and tracking, under the supervision of 
                    <a href="https://esa.rahtu.fi/"> Prof. Esa Rahtu</a> and <a href="https://www.oulu.fi/en/researchers/janne-heikkila"> Prof. Janne Heikkil√§</a>.
                  </p>

                  During my PhD, I was a guest researcher hosted by <a href="https://cvg.ethz.ch/team/Prof-Dr-Marc-Pollefeys"> Prof. Marc Pollefeys </a> in the <a href="https://cvg.ethz.ch/">CVG group at ETH Zurich</a>, 
                  collaborating with <a href="https://rozumden.github.io/">Dr. Denys Rozumny</a> and <a href="https://scholar.google.de/citations?user=biytQP8AAAAJ&hl=en">Prof. Martin R. Oswald</a> on simultaneous 6D object pose tracking and object reconstruction based on 3D Gaussian Splatting.
                  <p>
                    I obtained my Master's degree in Data Engineering and Signal Processing from Tampere University (formerly Tampere Univeristy of Technology) supervised by 
                    <a href="https://webpages.tuni.fi/vision/public_pages/JoniKamarainen/index.html">Prof. Joni K√§m√§r√§inen </a> 
                    and <a href="https://scholar.google.com/citations?user=pbNCoTwAAAAJ&hl=en"> Dr. Ke Chen </a> in 2017. Prior to that, I received my Bachelor's degree in Software Engineering in 2015, from Sichuan University, Chengdu, China.
                  </p>

                  
                  <!-- <p>I am a senior staff research scientist at <a href="https://ai.google/research">Google Research</a>, where I work on computer vision and machine learning. -->
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:caidingding815@gmail.com">Email (dingding.cai@tuni.fi) </a> &nbsp/&nbsp
                    <!-- <a href="mailto:jonbarron@gmail.com">Email</a> &nbsp/&nbsp -->
                    <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                    <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                     <a href="https://www.linkedin.com/in/dingding-cai-19b439b6/"> LinkedIn</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=rDG33HAAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                     <!-- &nbsp/&nbsp -->
                    <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                    <!-- <a href="https://github.com/jonbarron/">Github</a> -->
                    <!-- </br> dingding.cai@tuni.fi -->
                    <!-- <a href="images/CV_DingdingCai.pdf">CV</a> -->
                    <a href="images/CV_DingdingCai_20241108.pdf">CV</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/dingdingcai.jpg">
                    <img style="width:100%;max-width:100%" alt="profile photo" src="images/dingdingcai.jpg" class="hoverZoomLink">
                  </a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- research area -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    I'm interested in various 2D/3D computer vision tasks, in particular, 6D object pose estimation and tracking, 3D scene understanding, and 3D object reconstruction.
                     <!-- machine learning, optimization, and image processing.  -->
                    <!-- Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images.  -->
                    <!-- Representative papers are <span class="highlight">highlighted</span>. -->
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          
          <!-- GS-Pose -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nerfsuper_image'>
                      <video  width=100% height=100% muted autoplay loop>
                        <source src="gs-pose/gspose_icon.mp4" type="video/mp4">
                          Your browser does not support the video tag.
                      </video>
                    </div>
                    <!-- <img src='images/gspose.png' width="160"> -->
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="">
                  <!-- <a href="https://dingdingcai.github.io/gs-pose"> -->
                    <papertitle>GS-Pose: Generalizable Segmentation-based 6D Object Pose Estimation with 3D Gaussian Splatting</papertitle>
                  </a>
                  <br>
                  <strong>Dingding Cai</strong>, 
                  <a href="https://scholar.google.com/citations?user=SCR4RY8AAAAJ&hl=en">Janne Heikkil√§</a>,
                  <a href="https://scholar.google.com/citations?user=SmGZwHYAAAAJ&hl=en">Esa Rahtu</a>
                  <br>
                  <em>3DV</em>, 2025
                  <br>
                  <a href="https://dingdingcai.github.io/gs-pose">Project page</a> / 
                  <a href="https://arxiv.org/abs/2403.10683">Paper</a> / 
                  <a href="https://github.com/dingdingcai/GSPose">Code</a> 
                  <p>
                  We propose a unified framework for locating and estimating the 6D pose of novel objects. The proposed apporach leverages object co-segmentation and 3D Gaussian splatting for RGB-based 6D object pose estimation.
                  <!-- propose a practical self-supervised domain adaptation approach that takes advantage of real RGB(-D) data without needing real pose labels.  -->
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- MSDA -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='nerfsuper_image'>
                      <video  width=100% height=100% muted autoplay loop>
                        <source src="images/nerf_supervision.mp4" type="video/mp4">
                          Your browser does not support the video tag.
                      </video>
                    </div> -->
                    <img src='images/scia_2023.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://link.springer.com/chapter/10.1007/978-3-031-31438-4_31/">
                    <papertitle>MSDA: Monocular Self-supervised Domain Adaptation for 6D Object Pose Estimation</papertitle>
                  </a>
                  <br>
                  <strong>Dingding Cai</strong>, <a href="https://scholar.google.com/citations?user=SCR4RY8AAAAJ&hl=en">Janne Heikkil√§</a>,
                  <a href="https://scholar.google.com/citations?user=SmGZwHYAAAAJ&hl=en">Esa Rahtu</a>
                  <br>
                  <em>SCIA</em>, 2023 
                  <br>
                  <a href="https://link.springer.com/chapter/10.1007/978-3-031-31438-4_31">Paper</a>
                  <p>
                  We propose a practical self-supervised domain adaptation approach that takes advantage of real RGB(-D) data without needing real pose labels. 
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- SC6D -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='nerfsuper_image'>
                      <video  width=100% height=100% muted autoplay loop>
                        <source src="images/nerf_supervision.mp4" type="video/mp4">
                          Your browser does not support the video tag.
                      </video>
                    </div> -->
                    <img src='images/sc6d.png' width="160">
                  </div>
                  <!-- <script type="text/javascript">
                    function nerfsuper_start() {
                      document.getElementById('nerfsuper_image').style.opacity = "1";
                    }

                    function nerfsuper_stop() {
                      document.getElementById('nerfsuper_image').style.opacity = "0";
                    }
                    nerfsuper_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/dingdingcai/SC6D-pose/">
                    <papertitle>SC6D: Symmetry-agnostic and Correspondence-free 6D Object Pose Estimation</papertitle>
                  </a>
                  <br>
                  <!-- <a href="https://yenchenlin.me/">Lin Yen-Chen</a>,  -->
                  <!-- <a href="http://www.peteflorence.com/">Pete Florence</a>,  -->
                  <strong>Dingding Cai</strong>, <a href="https://scholar.google.com/citations?user=SCR4RY8AAAAJ&hl=en">Janne Heikkil√§</a>,
                  <a href="https://scholar.google.com/citations?user=SmGZwHYAAAAJ&hl=en">Esa Rahtu</a>
                  <br>
                  <em>3DV</em>, 2022  
                  <br>
                  <!-- <a href="https://dingdingcai.github.io/ove6d-pose/">Project page</a> /  -->
                  <a href="https://arxiv.org/abs/2208.02129">Paper</a> / 

                  <a href="https://github.com/dingdingcai/SC6D-pose">Code</a> 
                  
                  <!-- <a href="https://colab.research.google.com/drive/13ISri5KD2XeEtsFs25hmZtKhxoDywB5y?usp=sharing">colab</a>				 -->
                  <p>

                    We present an efficient symmetry-agnostic and correspondence-free framework, referred to as SC6D, for 6D object pose estimation 
                    from a single monocular RGB image. SC6D requires neither the 3D CAD model of the object nor any prior knowledge of the symmetries.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- OVE6D -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='nerfsuper_image'>
                      <video  width=100% height=100% muted autoplay loop>
                        <source src="images/nerf_supervision.mp4" type="video/mp4">
                          Your browser does not support the video tag.
                      </video>
                    </div> -->
                    <img src='images/ove6d.png' width="160">
                  </div>
                  <!-- <script type="text/javascript">
                    function nerfsuper_start() {
                      document.getElementById('nerfsuper_image').style.opacity = "1";
                    }

                    function nerfsuper_stop() {
                      document.getElementById('nerfsuper_image').style.opacity = "0";
                    }
                    nerfsuper_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://dingdingcai.github.io/ove6d-pose/">
                    <papertitle>OVE6D: Object Viewpoint Encoding for Depth-based 6D Object Pose Estimation</papertitle>
                  </a>
                  <br>
                  <!-- <a href="https://yenchenlin.me/">Lin Yen-Chen</a>,  -->
                  <!-- <a href="http://www.peteflorence.com/">Pete Florence</a>,  -->
                  <strong>Dingding Cai</strong>, <a href="https://scholar.google.com/citations?user=SCR4RY8AAAAJ&hl=en">Janne Heikkil√§</a>,
                  <a href="https://scholar.google.com/citations?user=SmGZwHYAAAAJ&hl=en">Esa Rahtu</a>
                  <!-- <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> -->
                  <br>
                  <em>CVPR</em>, 2022  
                  <br>
                  <a href="https://dingdingcai.github.io/ove6d-pose/">Project page</a> / 
                  <a href="https://arxiv.org/abs/2203.01072">Paper</a> / 

                  <!-- <a href="https://www.youtube.com/watch?v=_zN-wVwPH1s">video</a> / -->
                  <a href="https://github.com/dingdingcai/OVE6D-pose">Code</a> 
                  
                  <!-- <a href="https://colab.research.google.com/drive/13ISri5KD2XeEtsFs25hmZtKhxoDywB5y?usp=sharing">colab</a>				 -->
                  <p>
                    We propose a universal object 6D pose estimation model, called OVE6D, purely trained on synthetic 3D objects from ShapeNet 
                    and generalizing remarkably well to unseen objects without needing any parameter optimization.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          
          <!-- RACNN -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/racnn.png' width="160">
                  </div>

                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://www.sciencedirect.com/science/article/pii/S0167865517303896">
                    <papertitle>Convolutional Low-resolution Fine-grained Classification</papertitle>
                  </a>
                  <br>
                  <strong>Dingding Cai</strong>, <a href="https://scholar.google.com/citations?user=pbNCoTwAAAAJ&hl=en">Ke Chen</a>, 
                  <a href="https://scholar.google.fi/citations?user=EMnEhLIAAAAJ&hl=en">Yanlin Qian</a>, 
                  <a href="https://scholar.google.fi/citations?user=r6Y4nacAAAAJ&hl=en"> Joni-Kristian K√§m√§r√§inen</a>
                  <br>
                  <em>Pattern Recognition Letters</em>, 2019  
                  <br>
                  <a href="https://www.sciencedirect.com/science/article/pii/S0167865517303896">Paper</a> / 
                  <a href="https://github.com/dingdingcai/RACNN">Code</a> 
                  
                  <p>
                    We propose a novel resolution-aware deep model which combines convolutional image super-resolution and
                    convolutional fine-grained classification into a single model in an end-to-end manner.
                </td>
              </tr>
            
              

            </tbody>
          </table>

          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Misc</heading>
                </td>
              </tr>
            </tbody>
          </table> -->

          <!-- <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
                <td width="75%" valign="center">
                  <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                  <br>
                  <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
                  <br>
                  <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                  <br>
                  <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
                </td>
              </tr>
            </tbody>
          </table> -->
          <table style="height:300px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <!-- <heading>Acknowledgements</heading>
                  <p >
                    This webpage template is based on <a href="https://jonbarron.info" style="font-size:14px">link.</a>
                  </p> -->
                </td>
              </tr>
            </tbody>
          </table>
          
          <table class="pagefooter"  style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Acknowledgements</heading>
                  <p >
                    This webpage template is based on <a href="https://jonbarron.info" style="font-size:14px">link.</a>
                  </p>
                  
                  <!-- <p> -->
                    <!-- I'm interested in 3D scene understanding, object 6D pose estimation and tracking. -->
                     <!-- machine learning, optimization, and image processing.  -->
                    <!-- Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images.  -->
                    <!-- Representative papers are <span class="highlight">highlighted</span>. -->
                  <!-- </p> -->
                </td>
              </tr>
            </tbody>
          </table>


        </td>
      </tr>
  </table>

</body>

<!-- <div style="width:100%;max-width:800px;margin-right:auto;margin-left:auto;margin-bottom: 0%;"> -->
  <!-- <div class="pagefooter">
    <p style="font-size:14px">
      This webpage template is based on <a href="https://jonbarron.info" style="font-size:14px">link.</a>
    </p>
  </div> -->
<!-- </div> -->


</html>
